{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c051b9d4",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 读写文件\n",
    "\n",
    "到目前为止，我们讨论了如何处理数据，\n",
    "以及如何构建、训练和测试深度学习模型。\n",
    "然而，有时我们希望保存训练的模型，\n",
    "以备将来在各种环境中使用（比如在部署中进行预测）。\n",
    "此外，当运行一个耗时较长的训练过程时，\n",
    "最佳的做法是定期保存中间结果，\n",
    "以确保在服务器电源被不小心断掉时，我们不会损失几天的计算结果。\n",
    "因此，现在是时候学习如何加载和存储权重向量和整个模型了。\n",
    "\n",
    "## (**加载和保存张量**)\n",
    "\n",
    "对于单个张量，我们可以直接调用`load`和`save`函数分别读写它们。\n",
    "这两个函数都要求我们提供一个名称，`save`要求将要保存的变量作为输入。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e6b0eed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:57:14.320840Z",
     "iopub.status.busy": "2022-12-07T16:57:14.320234Z",
     "iopub.status.idle": "2022-12-07T16:57:15.480792Z",
     "shell.execute_reply": "2022-12-07T16:57:15.479939Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-10-20T09:15:19.507979100Z",
     "start_time": "2023-10-20T09:15:19.503992300Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "x = torch.arange(4)\n",
    "torch.save(x, 'x-file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4f0647",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "我们现在可以将存储在文件中的数据读回内存。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3dc6cc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:57:15.484795Z",
     "iopub.status.busy": "2022-12-07T16:57:15.484187Z",
     "iopub.status.idle": "2022-12-07T16:57:15.496200Z",
     "shell.execute_reply": "2022-12-07T16:57:15.495423Z"
    },
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-10-20T09:15:20.187684200Z",
     "start_time": "2023-10-20T09:15:20.182699600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 1, 2, 3])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.load('x-file')\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731e471f",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "我们可以[**存储一个张量列表，然后把它们读回内存。**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "816aa5cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:57:15.499724Z",
     "iopub.status.busy": "2022-12-07T16:57:15.499071Z",
     "iopub.status.idle": "2022-12-07T16:57:15.509309Z",
     "shell.execute_reply": "2022-12-07T16:57:15.508580Z"
    },
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-10-20T09:15:21.475311200Z",
     "start_time": "2023-10-20T09:15:21.466341400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros(4)\n",
    "torch.save([x, y],'x-files')\n",
    "x2, y2 = torch.load('x-files')\n",
    "(x2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41437ae",
   "metadata": {
    "origin_pos": 15
   },
   "source": [
    "我们甚至可以(**写入或读取从字符串映射到张量的字典**)。\n",
    "当我们要读取或写入模型中的所有权重时，这很方便。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa201bf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:57:15.512722Z",
     "iopub.status.busy": "2022-12-07T16:57:15.512205Z",
     "iopub.status.idle": "2022-12-07T16:57:15.519128Z",
     "shell.execute_reply": "2022-12-07T16:57:15.518294Z"
    },
    "origin_pos": 17,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-10-20T09:15:22.650517Z",
     "start_time": "2023-10-20T09:15:22.642544300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x': x, 'y': y}\n",
    "torch.save(mydict, 'mydict')\n",
    "mydict2 = torch.load('mydict')\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b23a493",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "## [**加载和保存模型参数**]\n",
    "\n",
    "保存单个权重向量（或其他张量）确实有用，\n",
    "但是如果我们想保存整个模型，并在以后加载它们，\n",
    "单独保存每个向量则会变得很麻烦。\n",
    "毕竟，我们可能有数百个参数散布在各处。\n",
    "因此，深度学习框架提供了内置函数来保存和加载整个网络。\n",
    "需要注意的一个重要细节是，这将保存模型的参数而不是保存整个模型。\n",
    "例如，如果我们有一个3层多层感知机，我们需要单独指定架构。\n",
    "因为模型本身可以包含任意代码，所以模型本身难以序列化。\n",
    "因此，为了恢复模型，我们需要用代码生成架构，\n",
    "然后从磁盘加载参数。\n",
    "让我们从熟悉的多层感知机开始尝试一下。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ca27a1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:57:15.522400Z",
     "iopub.status.busy": "2022-12-07T16:57:15.521895Z",
     "iopub.status.idle": "2022-12-07T16:57:15.528483Z",
     "shell.execute_reply": "2022-12-07T16:57:15.527720Z"
    },
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-10-20T09:15:26.700309100Z",
     "start_time": "2023-10-20T09:15:26.693332200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('hidden.weight',\n              tensor([[-0.0087, -0.1848,  0.1553,  ..., -0.1188,  0.0663, -0.0830],\n                      [-0.1022, -0.0578, -0.1459,  ..., -0.2110, -0.1539,  0.1704],\n                      [-0.1325,  0.1376, -0.0483,  ..., -0.0971, -0.0498,  0.1391],\n                      ...,\n                      [ 0.1105,  0.1052, -0.0087,  ..., -0.0370,  0.1158,  0.0049],\n                      [ 0.1285, -0.0358,  0.2226,  ...,  0.0528, -0.0622, -0.1326],\n                      [-0.0936, -0.0527,  0.1105,  ..., -0.0880,  0.1594, -0.1277]])),\n             ('hidden.bias',\n              tensor([ 0.2031,  0.2005,  0.1084,  0.0039,  0.2203,  0.1424,  0.1194,  0.0994,\n                      -0.0156,  0.1027, -0.1586,  0.0835, -0.0619, -0.1503, -0.0883,  0.1901,\n                       0.0430, -0.2120, -0.0566, -0.1722, -0.0879, -0.0447,  0.1558, -0.1566,\n                      -0.1869,  0.1681,  0.0573, -0.0856,  0.1947, -0.0113, -0.0207, -0.1896,\n                      -0.0455, -0.0065, -0.1452,  0.1618, -0.0585,  0.0342, -0.1132,  0.0932,\n                      -0.1211, -0.0501, -0.0904, -0.0901, -0.1567,  0.1701,  0.1631,  0.0031,\n                      -0.0481,  0.1535,  0.2010,  0.1225, -0.0580, -0.1520,  0.1104, -0.0645,\n                       0.1825,  0.1491,  0.0256, -0.1247,  0.1722, -0.0387,  0.2090,  0.1490,\n                       0.1432,  0.1083,  0.1268, -0.0423,  0.0697,  0.1970, -0.0459,  0.0774,\n                      -0.1673, -0.2190, -0.1220,  0.0227, -0.1999, -0.0832,  0.0107,  0.0599,\n                       0.1376,  0.1256,  0.0584, -0.0915,  0.0514,  0.0963, -0.1122, -0.1076,\n                       0.0757, -0.0787, -0.1366,  0.0853, -0.0270,  0.1491,  0.0917, -0.0778,\n                      -0.1014,  0.1840, -0.0024,  0.1736, -0.0243, -0.1057,  0.0908, -0.1874,\n                       0.2187, -0.1569,  0.2159, -0.1757, -0.0748, -0.1929,  0.0705, -0.1133,\n                       0.0540, -0.0154, -0.1498, -0.1698,  0.0377,  0.1150,  0.0568,  0.0267,\n                       0.2148, -0.0963, -0.0345, -0.0250, -0.1417, -0.1429, -0.1702,  0.2146,\n                       0.0524, -0.0082,  0.0035,  0.0936, -0.1559,  0.0471, -0.1374,  0.1693,\n                      -0.0558, -0.1595, -0.0460,  0.1240, -0.2198, -0.1971,  0.2107,  0.0928,\n                       0.1562,  0.0065, -0.1401,  0.1290,  0.2033, -0.2021, -0.1303,  0.1363,\n                       0.0124,  0.0423,  0.0121, -0.1074, -0.0327,  0.2041,  0.1383,  0.1617,\n                       0.0686,  0.0827, -0.0356,  0.1117,  0.0410,  0.0250,  0.1880,  0.0378,\n                      -0.0089,  0.1218, -0.0770,  0.2209, -0.1992, -0.0420, -0.0547,  0.1007,\n                       0.0119, -0.2231,  0.0203,  0.1812,  0.0297,  0.0796, -0.2007,  0.1155,\n                       0.0745,  0.0780,  0.0625, -0.1721,  0.1447, -0.0959, -0.0611, -0.1393,\n                       0.2206, -0.1306,  0.0591,  0.1237,  0.1055,  0.0871,  0.0829, -0.1927,\n                       0.0260,  0.0216,  0.0585,  0.1892,  0.0451,  0.0099, -0.1442, -0.0178,\n                      -0.1143,  0.1359, -0.1179,  0.0045, -0.0149,  0.1818,  0.1328, -0.0367,\n                      -0.1101,  0.0644, -0.2050, -0.0795,  0.0731,  0.0849,  0.0853,  0.1354,\n                      -0.0034,  0.0034,  0.0690, -0.0069,  0.0120, -0.1663, -0.0079, -0.1289,\n                       0.0426, -0.2167,  0.1014, -0.0420, -0.1808, -0.0959,  0.1883,  0.0088,\n                      -0.0204, -0.0657,  0.0101,  0.0451, -0.1856,  0.1074,  0.1935, -0.1500,\n                       0.1835, -0.0958, -0.0392, -0.1838, -0.0825, -0.1641,  0.2035,  0.1509])),\n             ('output.weight',\n              tensor([[ 0.0111,  0.0193,  0.0103,  ...,  0.0501, -0.0028,  0.0224],\n                      [-0.0437,  0.0564, -0.0578,  ...,  0.0255,  0.0330,  0.0323],\n                      [ 0.0314,  0.0107, -0.0471,  ...,  0.0272, -0.0622,  0.0594],\n                      ...,\n                      [-0.0213, -0.0422, -0.0241,  ...,  0.0302, -0.0606, -0.0013],\n                      [ 0.0351,  0.0452, -0.0538,  ..., -0.0155, -0.0278, -0.0547],\n                      [-0.0243,  0.0609,  0.0042,  ...,  0.0380,  0.0390,  0.0232]])),\n             ('output.bias',\n              tensor([-0.0073,  0.0472, -0.0563, -0.0412,  0.0181,  0.0615,  0.0443,  0.0293,\n                       0.0021, -0.0540]))])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)\n",
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d6c38",
   "metadata": {
    "origin_pos": 25
   },
   "source": [
    "接下来，我们[**将模型的参数存储在一个叫做“mlp.params”的文件中。**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "970045b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:57:15.531616Z",
     "iopub.status.busy": "2022-12-07T16:57:15.531209Z",
     "iopub.status.idle": "2022-12-07T16:57:15.535898Z",
     "shell.execute_reply": "2022-12-07T16:57:15.535152Z"
    },
    "origin_pos": 27,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-10-20T08:39:44.927922900Z",
     "start_time": "2023-10-20T08:39:44.922939400Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'mlp.params')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70324442",
   "metadata": {
    "origin_pos": 30
   },
   "source": [
    "为了恢复模型，我们[**实例化了原始多层感知机模型的一个备份。**]\n",
    "这里我们不需要随机初始化模型参数，而是(**直接读取文件中存储的参数。**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90e3ee76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:57:15.539128Z",
     "iopub.status.busy": "2022-12-07T16:57:15.538719Z",
     "iopub.status.idle": "2022-12-07T16:57:15.545525Z",
     "shell.execute_reply": "2022-12-07T16:57:15.544793Z"
    },
    "origin_pos": 32,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-10-20T08:39:47.303062600Z",
     "start_time": "2023-10-20T08:39:47.294093100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "MLP(\n  (hidden): Linear(in_features=20, out_features=256, bias=True)\n  (output): Linear(in_features=256, out_features=10, bias=True)\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debe75e6",
   "metadata": {
    "origin_pos": 35
   },
   "source": [
    "由于两个实例具有相同的模型参数，在输入相同的`X`时，\n",
    "两个实例的计算结果应该相同。\n",
    "让我们来验证一下。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2c4d08d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:57:15.549346Z",
     "iopub.status.busy": "2022-12-07T16:57:15.548468Z",
     "iopub.status.idle": "2022-12-07T16:57:15.555963Z",
     "shell.execute_reply": "2022-12-07T16:57:15.555173Z"
    },
    "origin_pos": 37,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-10-20T08:39:48.739200300Z",
     "start_time": "2023-10-20T08:39:48.729234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[True, True, True, True, True, True, True, True, True, True],\n        [True, True, True, True, True, True, True, True, True, True]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "test = {\"a\":torch.rand((3,2)),\"model\": net}\n",
    "torch.save(test, \"abc.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T08:41:25.100828700Z",
     "start_time": "2023-10-20T08:41:25.094849Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        ...,\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True]])\n",
      "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True])\n",
      "tensor([[True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        ...,\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True],\n",
      "        [True, True, True,  ..., True, True, True]])\n",
      "tensor([True, True, True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "a = torch.load(\"abc.pt\")\n",
    "for i,j in zip(a.get(\"model\").parameters(), net.parameters()):\n",
    "    print(i.data == j.data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T08:53:10.289419900Z",
     "start_time": "2023-10-20T08:53:10.283440300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "5c2a18cb",
   "metadata": {
    "origin_pos": 39
   },
   "source": [
    "## 小结\n",
    "\n",
    "* `save`和`load`函数可用于张量对象的文件读写。\n",
    "* 我们可以通过参数字典保存和加载网络的全部参数。\n",
    "* 保存架构必须在代码中完成，而不是在参数中完成。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 即使不需要将经过训练的模型部署到不同的设备上，存储模型参数还有什么实际的好处？\n",
    "1. 假设我们只想复用网络的一部分，以将其合并到不同的网络架构中。比如想在一个新的网络中使用之前网络的前两层，该怎么做？\n",
    "1. 如何同时保存网络架构和参数？需要对架构加上什么限制？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0edd9a9",
   "metadata": {
    "origin_pos": 41,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/1839)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
