{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c051b9d4",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 读写文件\n",
    "\n",
    "到目前为止，我们讨论了如何处理数据，\n",
    "以及如何构建、训练和测试深度学习模型。\n",
    "然而，有时我们希望保存训练的模型，\n",
    "以备将来在各种环境中使用（比如在部署中进行预测）。\n",
    "此外，当运行一个耗时较长的训练过程时，\n",
    "最佳的做法是定期保存中间结果，\n",
    "以确保在服务器电源被不小心断掉时，我们不会损失几天的计算结果。\n",
    "因此，现在是时候学习如何加载和存储权重向量和整个模型了。\n",
    "\n",
    "## (**加载和保存张量**)\n",
    "\n",
    "对于单个张量，我们可以直接调用`load`和`save`函数分别读写它们。\n",
    "这两个函数都要求我们提供一个名称，`save`要求将要保存的变量作为输入。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e6b0eed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:57:14.320840Z",
     "iopub.status.busy": "2022-12-07T16:57:14.320234Z",
     "iopub.status.idle": "2022-12-07T16:57:15.480792Z",
     "shell.execute_reply": "2022-12-07T16:57:15.479939Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-08-12T08:15:46.326287400Z",
     "start_time": "2023-08-12T08:15:46.318830400Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "x = torch.arange(4)\n",
    "torch.save(x, 'x-file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4f0647",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "我们现在可以将存储在文件中的数据读回内存。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3dc6cc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:57:15.484795Z",
     "iopub.status.busy": "2022-12-07T16:57:15.484187Z",
     "iopub.status.idle": "2022-12-07T16:57:15.496200Z",
     "shell.execute_reply": "2022-12-07T16:57:15.495423Z"
    },
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-08-12T08:15:47.002099500Z",
     "start_time": "2023-08-12T08:15:46.990976500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 1, 2, 3])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.load('x-file')\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731e471f",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "我们可以[**存储一个张量列表，然后把它们读回内存。**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "816aa5cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:57:15.499724Z",
     "iopub.status.busy": "2022-12-07T16:57:15.499071Z",
     "iopub.status.idle": "2022-12-07T16:57:15.509309Z",
     "shell.execute_reply": "2022-12-07T16:57:15.508580Z"
    },
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-08-12T08:15:48.111841600Z",
     "start_time": "2023-08-12T08:15:48.100708300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros(4)\n",
    "torch.save([x, y],'x-files')\n",
    "x2, y2 = torch.load('x-files')\n",
    "(x2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41437ae",
   "metadata": {
    "origin_pos": 15
   },
   "source": [
    "我们甚至可以(**写入或读取从字符串映射到张量的字典**)。\n",
    "当我们要读取或写入模型中的所有权重时，这很方便。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa201bf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:57:15.512722Z",
     "iopub.status.busy": "2022-12-07T16:57:15.512205Z",
     "iopub.status.idle": "2022-12-07T16:57:15.519128Z",
     "shell.execute_reply": "2022-12-07T16:57:15.518294Z"
    },
    "origin_pos": 17,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-08-12T08:20:48.805679200Z",
     "start_time": "2023-08-12T08:20:48.799698400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'x': {'x': tensor([0, 1, 2, 3]), 'y': tensor([0, 1])}, 'y': tensor([0, 1])}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x': x, 'y': y}\n",
    "torch.save(mydict, 'mydict')\n",
    "mydict2 = torch.load('mydict')\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b23a493",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "## [**加载和保存模型参数**]\n",
    "\n",
    "保存单个权重向量（或其他张量）确实有用，\n",
    "但是如果我们想保存整个模型，并在以后加载它们，\n",
    "单独保存每个向量则会变得很麻烦。\n",
    "毕竟，我们可能有数百个参数散布在各处。\n",
    "因此，深度学习框架提供了内置函数来保存和加载整个网络。\n",
    "需要注意的一个重要细节是，这将保存模型的参数而不是保存整个模型。\n",
    "例如，如果我们有一个3层多层感知机，我们需要单独指定架构。\n",
    "因为模型本身可以包含任意代码，所以模型本身难以序列化。\n",
    "因此，为了恢复模型，我们需要用代码生成架构，\n",
    "然后从磁盘加载参数。\n",
    "让我们从熟悉的多层感知机开始尝试一下。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ca27a1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:57:15.522400Z",
     "iopub.status.busy": "2022-12-07T16:57:15.521895Z",
     "iopub.status.idle": "2022-12-07T16:57:15.528483Z",
     "shell.execute_reply": "2022-12-07T16:57:15.527720Z"
    },
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-08-12T08:24:11.996803200Z",
     "start_time": "2023-08-12T08:24:11.985840200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('hidden.weight',\n              tensor([[ 0.0789, -0.1832, -0.0476,  ...,  0.1467, -0.2235, -0.1201],\n                      [ 0.1073, -0.0392,  0.1710,  ..., -0.2153, -0.0470, -0.1183],\n                      [-0.1342, -0.0709,  0.1688,  ...,  0.1824, -0.0742, -0.0873],\n                      ...,\n                      [ 0.1184, -0.2174,  0.1200,  ..., -0.1174,  0.1743,  0.1142],\n                      [-0.1800, -0.2165, -0.0403,  ..., -0.1324,  0.1556, -0.1485],\n                      [ 0.1012, -0.1164,  0.0501,  ...,  0.1458,  0.0806, -0.2014]])),\n             ('hidden.bias',\n              tensor([-4.7774e-02, -9.6838e-02, -1.7811e-01, -2.5280e-02,  8.6918e-02,\n                      -3.1911e-02, -1.4564e-01,  2.0318e-01, -3.5491e-02, -3.3230e-02,\n                       1.5940e-01, -8.3800e-02,  1.6973e-01, -2.8260e-02,  1.2623e-01,\n                       2.2239e-01,  5.5568e-03, -1.2072e-01,  2.1272e-01,  5.0839e-02,\n                       1.6453e-01, -1.7069e-01, -1.3720e-01,  1.7142e-02,  1.1616e-01,\n                      -1.6633e-01, -1.3066e-03, -1.2499e-01,  2.1001e-01, -2.1625e-01,\n                       1.1364e-01,  1.9626e-01,  1.3014e-01, -1.0464e-01, -1.5061e-01,\n                       2.8226e-02,  1.5299e-01, -4.8313e-03, -1.6483e-01, -1.4991e-01,\n                       8.6687e-02,  1.0229e-01, -1.2349e-01, -2.0268e-01, -1.0066e-01,\n                      -5.2510e-02,  3.9513e-02, -6.9257e-02,  1.6666e-01, -5.0699e-02,\n                       1.3313e-01, -4.9277e-02, -4.8933e-02, -1.3308e-01, -1.2847e-01,\n                       1.3715e-01,  8.5481e-02, -1.5804e-02,  2.1509e-01, -7.8336e-02,\n                       1.2746e-01, -2.0733e-01, -3.6387e-02,  1.3028e-01, -1.4258e-01,\n                      -1.0882e-01, -2.1511e-01,  1.7545e-01,  1.0130e-01, -5.2398e-02,\n                       7.1620e-02, -1.2430e-01, -1.1106e-01,  1.7933e-01, -4.3295e-03,\n                       8.7839e-02, -1.9766e-01,  1.5422e-01,  7.1942e-02, -9.4079e-02,\n                      -2.0628e-01,  9.6014e-02,  1.0383e-01,  1.8221e-02, -1.5819e-01,\n                       7.6065e-02,  3.3766e-02, -1.3973e-01, -7.0684e-02,  1.1840e-01,\n                      -7.6948e-04,  5.9755e-02, -5.2548e-02, -1.5104e-01,  1.1410e-02,\n                       1.5105e-02,  4.6272e-02,  8.6336e-02,  6.6586e-02, -5.4729e-02,\n                      -1.0505e-01,  5.4320e-02,  4.3015e-02, -1.7865e-01, -5.5913e-02,\n                      -1.1908e-01,  1.5547e-01,  1.7624e-01, -2.0556e-01, -2.9783e-02,\n                       1.3048e-01,  1.9129e-01,  1.1150e-01,  1.1833e-01, -1.0182e-01,\n                      -4.9345e-02, -1.7580e-01, -2.0040e-01,  1.2827e-01,  1.7932e-01,\n                       1.1582e-01,  5.7203e-02, -1.5727e-01, -1.8631e-01,  1.8944e-01,\n                       1.0038e-01, -2.1771e-01, -5.9550e-02,  1.5080e-01, -2.6704e-02,\n                       9.5863e-02,  1.5325e-01,  8.0474e-02,  2.2021e-01, -1.1081e-01,\n                       1.0563e-02, -1.3122e-01, -2.1595e-01, -5.3609e-02, -7.4252e-02,\n                       6.5839e-02,  1.2434e-01,  1.2555e-01, -1.2290e-01, -1.1629e-01,\n                       1.3911e-01, -1.8430e-01, -1.8201e-01, -2.5839e-02, -2.0027e-01,\n                      -7.5854e-02, -1.5973e-01,  8.8605e-02,  2.1875e-01,  2.9975e-02,\n                       1.9714e-01, -1.4527e-01, -4.2175e-02, -1.9046e-01,  1.7440e-01,\n                      -3.9802e-03, -3.9388e-02, -1.7528e-01, -4.8764e-03, -1.1699e-01,\n                      -1.9696e-01,  1.9599e-01, -2.1207e-01, -1.1226e-01, -6.2730e-02,\n                       1.1680e-01, -2.1941e-01,  1.3375e-01, -5.6716e-02, -2.2172e-01,\n                      -1.6255e-01, -5.4117e-02,  1.6519e-01,  1.3455e-01, -1.4788e-01,\n                      -1.1974e-01,  1.6386e-01, -3.9104e-02, -1.5441e-01,  2.3484e-02,\n                       1.7642e-01, -2.3558e-02,  1.3318e-01,  7.1719e-02,  1.3209e-01,\n                       7.8405e-02,  1.9252e-01, -3.9624e-02, -1.9573e-01,  9.4113e-02,\n                       1.2696e-01, -1.0955e-02, -1.3720e-01, -7.5852e-02, -1.2853e-01,\n                      -1.4749e-01,  5.1965e-02, -2.6586e-02,  6.9611e-02, -1.0527e-01,\n                       1.4703e-01,  1.9245e-01,  5.8267e-02, -2.2134e-01,  1.9055e-01,\n                      -9.8399e-02, -1.3079e-01, -3.7440e-02,  6.9116e-02,  5.7751e-02,\n                      -1.2048e-01,  1.2172e-01,  8.0767e-02, -1.9345e-01, -1.0708e-01,\n                       1.9653e-01, -9.1391e-02, -2.1095e-01,  5.6986e-02,  1.5457e-01,\n                      -4.6346e-02, -1.3126e-01,  3.0589e-03,  8.9910e-03,  1.7033e-01,\n                       1.0767e-01, -9.5094e-02, -2.5751e-02, -1.5343e-01, -7.1843e-02,\n                       4.6460e-02,  9.5929e-02,  4.6554e-02,  1.5577e-01, -1.8413e-01,\n                      -3.8905e-02,  2.0178e-01,  1.0087e-01, -1.7093e-01,  6.6095e-02,\n                      -1.5327e-01,  4.3929e-02, -8.8989e-03,  7.3404e-02,  1.8377e-01,\n                      -9.5159e-02, -3.2682e-02,  1.4541e-04,  1.2060e-01, -1.6767e-02,\n                      -1.1871e-02])),\n             ('output.weight',\n              tensor([[-5.8009e-02,  1.5580e-02, -4.0405e-02,  ..., -4.5865e-03,\n                       -2.2237e-02,  2.1003e-02],\n                      [ 8.5307e-03,  3.2440e-02,  6.2318e-02,  ...,  3.2795e-02,\n                        3.7956e-02,  1.1097e-02],\n                      [ 2.2715e-02, -5.5412e-02,  5.2802e-02,  ...,  4.9130e-02,\n                       -7.1658e-03, -9.6191e-03],\n                      ...,\n                      [ 1.5527e-05,  4.9378e-02,  4.2915e-02,  ..., -2.5778e-02,\n                       -1.3731e-02, -6.0481e-02],\n                      [-5.6187e-03,  1.2888e-02, -3.2732e-02,  ...,  1.5914e-02,\n                       -5.6971e-02,  2.4350e-02],\n                      [ 3.7130e-02, -2.9366e-02, -2.6568e-02,  ...,  2.4936e-02,\n                        3.2625e-02,  2.6303e-03]])),\n             ('output.bias',\n              tensor([-0.0320,  0.0343,  0.0424, -0.0617,  0.0233, -0.0331,  0.0182, -0.0545,\n                      -0.0139, -0.0224]))])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)\n",
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d6c38",
   "metadata": {
    "origin_pos": 25
   },
   "source": [
    "接下来，我们[**将模型的参数存储在一个叫做“mlp.params”的文件中。**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "970045b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:57:15.531616Z",
     "iopub.status.busy": "2022-12-07T16:57:15.531209Z",
     "iopub.status.idle": "2022-12-07T16:57:15.535898Z",
     "shell.execute_reply": "2022-12-07T16:57:15.535152Z"
    },
    "origin_pos": 27,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-08-12T08:24:13.299651600Z",
     "start_time": "2023-08-12T08:24:13.295658500Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'mlp.params')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70324442",
   "metadata": {
    "origin_pos": 30
   },
   "source": [
    "为了恢复模型，我们[**实例化了原始多层感知机模型的一个备份。**]\n",
    "这里我们不需要随机初始化模型参数，而是(**直接读取文件中存储的参数。**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90e3ee76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:57:15.539128Z",
     "iopub.status.busy": "2022-12-07T16:57:15.538719Z",
     "iopub.status.idle": "2022-12-07T16:57:15.545525Z",
     "shell.execute_reply": "2022-12-07T16:57:15.544793Z"
    },
    "origin_pos": 32,
    "tab": [
     "pytorch"
    ],
    "ExecuteTime": {
     "end_time": "2023-08-12T08:25:13.224130500Z",
     "start_time": "2023-08-12T08:25:13.210748300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "MLP(\n  (hidden): Linear(in_features=20, out_features=256, bias=True)\n  (output): Linear(in_features=256, out_features=10, bias=True)\n)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debe75e6",
   "metadata": {
    "origin_pos": 35
   },
   "source": [
    "由于两个实例具有相同的模型参数，在输入相同的`X`时，\n",
    "两个实例的计算结果应该相同。\n",
    "让我们来验证一下。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c4d08d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:57:15.549346Z",
     "iopub.status.busy": "2022-12-07T16:57:15.548468Z",
     "iopub.status.idle": "2022-12-07T16:57:15.555963Z",
     "shell.execute_reply": "2022-12-07T16:57:15.555173Z"
    },
    "origin_pos": 37,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a18cb",
   "metadata": {
    "origin_pos": 39
   },
   "source": [
    "## 小结\n",
    "\n",
    "* `save`和`load`函数可用于张量对象的文件读写。\n",
    "* 我们可以通过参数字典保存和加载网络的全部参数。\n",
    "* 保存架构必须在代码中完成，而不是在参数中完成。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 即使不需要将经过训练的模型部署到不同的设备上，存储模型参数还有什么实际的好处？\n",
    "1. 假设我们只想复用网络的一部分，以将其合并到不同的网络架构中。比如想在一个新的网络中使用之前网络的前两层，该怎么做？\n",
    "1. 如何同时保存网络架构和参数？需要对架构加上什么限制？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0edd9a9",
   "metadata": {
    "origin_pos": 41,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/1839)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
